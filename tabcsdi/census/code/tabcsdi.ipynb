{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9800848,"sourceType":"datasetVersion","datasetId":6006700},{"sourceId":9813494,"sourceType":"datasetVersion","datasetId":6016311},{"sourceId":9844052,"sourceType":"datasetVersion","datasetId":6039515}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### File operation","metadata":{}},{"cell_type":"code","source":"# census, 9 categorical feature; 6 numerical features; total 20000 samples.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cp -r /kaggle/input/census-dataset/ /kaggle/working/census_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rm -rf /kaggle/working/census_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Set parameters and import package","metadata":{}},{"cell_type":"code","source":"import re\nimport os\nimport math\nimport json\nimport yaml\nimport torch\nimport pickle\nimport argparse\nimport datetime\nimport typing as ty\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport torch.nn as nn\nfrom torch import Tensor\nfrom torch.optim import Adam\nimport torch.nn.init as nn_init\nimport category_encoders as ce\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parser= argparse.ArgumentParser(description= \"TabCSDI\")\nparser.add_argument(\"--device\", default= 'cpu', help= \"Device\")\nparser.add_argument(\"--seed\", type= int, default= 1)\nparser.add_argument(\"--testmissingratio\", type= float, default= 0.2)\nparser.add_argument(\"--nfold\", type= int, default= 5, help= \"for 5-fold test\")\nparser.add_argument(\"--unconditional\", action= \"store_true\", default= 0)\nparser.add_argument(\"--modelfolder\", type= str, default= \"\")\nparser.add_argument(\"--nsample\", type= int, default= 100)\nargs= parser.parse_args([])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load data","metadata":{}},{"cell_type":"code","source":"def process_func(path= \"/kaggle/working/census_dataset/adult_trim.data\", cat_list= [1, 3, 5, 6, 7, 8, 9, 13, 14], missing_ratio= 0.1, encode= True):\n    data= pd.read_csv(path, header= None)\n    # Swap columns\n    temp_list= [i for i in range(data.shape[1]) if i not in cat_list]\n    temp_list.extend(cat_list)\n    new_cols_order= temp_list\n    data= data.reindex(columns= data.columns[new_cols_order])\n    data.columns= [i for i in range(data.shape[1])]\n    # create two lists to store position\n    cont_list= [i for i in range(0, data.shape[1]- len(cat_list))] # continuous features index\n    cat_list= [i for i in range(len(cont_list), data.shape[1])] # catlogue features index\n    observed_values= data.values\n    observed_masks= ~pd.isnull(data)\n    observed_masks= observed_masks.values\n    masks= observed_masks.copy()\n    # In this section, obtain gt_masks\n    # for each column, mask `missing_ratio` % of observed values.\n    for col in range(masks.shape[1]):\n        obs_indices= np.where(masks[:, col])[0]\n        miss_indices= np.random.choice(obs_indices, (int)(len(obs_indices) * missing_ratio), replace= False)\n        masks[miss_indices, col]= False\n    # gt_mask: 0 for missing elements and manully maksed elements\n    gt_masks= masks.reshape(observed_masks.shape)\n    num_cate_list= []\n    if encode== True:\n        # set encoder here\n        encoder= ce.ordinal.OrdinalEncoder(cols= data.columns[cat_list])\n        encoder.fit(data)\n        new_df= encoder.transform(data)\n        # we now need to transform these masks to the new one, suitable for mixed data types.\n        cum_num_bits= 0\n        new_observed_masks= observed_masks.copy()\n        new_gt_masks= gt_masks.copy()\n        for index, col in enumerate(cat_list):\n            num_cate_list.append(new_df.iloc[:, col].nunique())\n            corresponding_cols= len(\n                [s for s in new_df.columns if isinstance(s, str) and s.startswith(str(col) + \"_\")]\n            )\n            add_col_num= corresponding_cols\n            insert_col_obs= observed_masks[:, col]\n            insert_col_gt= gt_masks[:, col]\n            for i in range(add_col_num- 1):\n                new_observed_masks= np.insert(\n                    new_observed_masks, cum_num_bits+ col, insert_col_obs, axis= 1\n                )\n                new_gt_masks= np.insert(\n                    new_gt_masks, cum_num_bits+ col, insert_col_gt, axis= 1\n                )\n            cum_num_bits+= add_col_num- 1\n        new_observed_values= new_df.values\n        new_observed_values= np.nan_to_num(new_observed_values)\n        new_observed_values= new_observed_values.astype(float)\n        with open(\"./census_dataset/transformed_columns.pk\", \"wb\") as f:\n            pickle.dump([cont_list, num_cate_list], f)\n        with open(\"./census_dataset/encoder.pk\", \"wb\") as f:\n            pickle.dump(encoder, f)\n    if encode== True:\n        return new_observed_values, new_observed_masks, new_gt_masks, cont_list\n    else:\n        cont_cols= [i for i in data.columns if i not in cat_list]\n        return observed_values, observed_masks, gt_masks, cont_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class tabular_Dataset(Dataset):\n    # eval_length should be equal to attributes number.\n    def __init__(self, eval_length= 15, use_index_list= None, missing_ratio= 0.1, seed= 0):\n        self.eval_length= eval_length\n        np.random.seed(seed)\n        dataset_path= \"./census_dataset/adult_trim.data\"\n        processed_data_path= (f\"./census_dataset/missing_ratio-{missing_ratio}_seed-{seed}.pk\")\n        processed_data_path_norm= f\"./census_dataset/missing_ratio-{missing_ratio}_seed-{seed}_max-min_norm.pk\"\n        # self.cont_cols is only saved in .pk file before normalization.\n        cat_list= [1, 3, 5, 6, 7, 8, 9, 13, 14]\n        if not os.path.isfile(processed_data_path):\n            (self.observed_values, self.observed_masks, self.gt_masks, self.cont_cols,)= process_func(dataset_path, cat_list= cat_list, missing_ratio= missing_ratio, encode= True,)\n            with open(processed_data_path, \"wb\") as f:\n                pickle.dump([self.observed_values, self.observed_masks, self.gt_masks, self.cont_cols,], f,)\n            print(\"--------Dataset created--------\")\n        elif os.path.isfile(processed_data_path_norm):  # load datasetfile\n            with open(processed_data_path_norm, \"rb\") as f:\n                self.observed_values, self.observed_masks, self.gt_masks= pickle.load(f)\n            print(\"--------Normalized dataset loaded--------\")\n        if use_index_list is None:\n            self.use_index_list= np.arange(len(self.observed_values))\n        else:\n            self.use_index_list= use_index_list\n\n    def __getitem__(self, org_index):\n        index= self.use_index_list[org_index]\n        s= {\n            \"observed_data\": self.observed_values[index],\n            \"observed_mask\": self.observed_masks[index],\n            \"gt_mask\": self.gt_masks[index],\n            \"timepoints\": np.arange(self.eval_length),\n        }\n        return s\n\n    def __len__(self):\n        return len(self.use_index_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataloader(seed= 1, nfold= 5, batch_size= 128, missing_ratio= 0.1):\n    dataset= tabular_Dataset(missing_ratio= missing_ratio, seed= seed)\n    print(f\"Dataset size:{len(dataset)} entries\")\n    indlist= np.arange(len(dataset))\n    np.random.seed(seed + 1)\n    np.random.shuffle(indlist)\n    tmp_ratio= 1/ nfold\n    start= (int)((nfold- 1)* len(dataset)* tmp_ratio)\n    end= (int)(nfold* len(dataset)* tmp_ratio)\n    test_index= indlist[start: end]\n    remain_index= np.delete(indlist, np.arange(start, end))\n    np.random.shuffle(remain_index)\n    num_train= (int)(len(remain_index)* 0.8)\n    train_index= remain_index[:num_train]\n    valid_index= remain_index[num_train:]\n    # Here we perform max-min normalization.\n    processed_data_path_norm= (f\"./census_dataset/missing_ratio-{missing_ratio}_seed-{seed}_max-min_norm.pk\")\n    if not os.path.isfile(processed_data_path_norm):\n        print(\"--------------Dataset has not been normalized yet. Perform data normalization and store the mean value of each column.--------------\")\n        # data transformation after train-test split.\n        col_num= len(dataset.cont_cols)\n        max_arr= np.zeros(col_num)\n        min_arr= np.zeros(col_num)\n        mean_arr= np.zeros(col_num)\n        for index, k in enumerate(dataset.cont_cols):\n            # Using observed_mask to avoid counting missing values (now represented as 0)\n            obs_ind= dataset.observed_masks[train_index, k].astype(bool)\n            temp= dataset.observed_values[train_index, k]\n            max_arr[index]= max(temp[obs_ind])\n            min_arr[index]= min(temp[obs_ind])\n        print(f\"--------------Max-value for cont-variable column {max_arr}--------------\")\n        print(f\"--------------Min-value for cont-variable column {min_arr}--------------\")\n        for index, k in enumerate(dataset.cont_cols):\n            dataset.observed_values[:, k]= (\n                (dataset.observed_values[:, k]- (min_arr[index]- 1))/ (max_arr[index]- min_arr[index]+ 1)\n            )* dataset.observed_masks[:, k]\n        with open(processed_data_path_norm, \"wb\") as f:\n            pickle.dump([dataset.observed_values, dataset.observed_masks, dataset.gt_masks], f)\n    # Now the path exists, so the dataset object initialization performs data loading.\n    train_dataset= tabular_Dataset(use_index_list= train_index, missing_ratio= missing_ratio, seed= seed)\n    train_loader= DataLoader(train_dataset, batch_size= batch_size, shuffle= 1)\n    valid_dataset= tabular_Dataset(use_index_list= valid_index, missing_ratio= missing_ratio, seed= seed)\n    valid_loader= DataLoader(valid_dataset, batch_size= batch_size, shuffle= 0)\n    test_dataset= tabular_Dataset(use_index_list= test_index, missing_ratio= missing_ratio, seed= seed)\n    test_loader= DataLoader(test_dataset, batch_size= batch_size, shuffle= 0)\n    print(f\"Training dataset size: {len(train_dataset)}\")\n    print(f\"Validation dataset size: {len(valid_dataset)}\")\n    print(f\"Testing dataset size: {len(test_dataset)}\")\n    return train_loader, valid_loader, test_loader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader, valid_loader, test_loader= get_dataloader(seed= 1, nfold= 5, batch_size= 128, missing_ratio= 0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Set parameters","metadata":{}},{"cell_type":"code","source":"config= {\n    \"train\": {\n        \"epochs\": 250,\n        \"batch_size\": 128,\n        \"lr\": 0.0005\n    },\n    \"diffusion\": {\n        \"layers\": 4,\n        \"channels\": 128,\n        \"nheads\": 4,\n        \"diffusion_embedding_dim\": 128,\n        \"beta_start\": 0.0001,\n        \"beta_end\": 0.5,\n        \"num_steps\": 100,\n        \"schedule\": \"quad\",\n        \"mixed\": True,\n        \"token_emb_dim\": 8\n    },\n    \"model\": {\n        \"is_unconditional\": 0,\n        \"timeemb\": 128,\n        \"featureemb\": 8,\n        \"target_strategy\": \"random\",\n        \"mixed\": True,\n        \"token_emb_dim\": 8\n    }\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config[\"model\"][\"is_unconditional\"]= args.unconditional\nconfig[\"model\"][\"test_missing_ratio\"]= args.testmissingratio","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model module","metadata":{}},{"cell_type":"code","source":"# partially stole from https://github.com/Yura52/tabular-dl-revisiting-models/blob/main/bin/ft_transformer.py\nclass Tokenizer(nn.Module):\n    def __init__(self, d_numerical: int, categories: ty.Optional[ty.List[int]], d_token: int, bias: bool,)-> None:\n        super().__init__()\n        d_bias= d_numerical+ len(categories)\n        category_offsets= torch.tensor([0]+ categories[:-1]).cumsum(0)\n        self.d_token= d_token\n        self.register_buffer(\"category_offsets\", category_offsets)\n        self.category_embeddings= nn.Embedding(sum(categories)+ 1, self.d_token)\n        self.category_embeddings.weight.requires_grad= False\n        nn_init.kaiming_uniform_(self.category_embeddings.weight, a= math.sqrt(5))\n        self.weight= nn.Parameter(Tensor(d_numerical, self.d_token))\n        self.weight.requires_grad= False\n        self.bias= nn.Parameter(Tensor(d_bias, self.d_token)) if bias else None\n        nn_init.kaiming_uniform_(self.weight, a= math.sqrt(5))\n        if self.bias is not None:\n            nn_init.kaiming_uniform_(self.bias, a= math.sqrt(5))\n            self.bias.requires_grad= False\n    @property\n    def n_tokens(self)-> int:\n        return len(self.weight)+ (0 if self.category_offsets is None else len(self.category_offsets))\n\n    def forward(self, x_num: Tensor, x_cat: ty.Optional[Tensor])-> Tensor:\n        x_some= x_num if x_cat is None else x_cat\n        x_cat= x_cat.type(torch.int32)\n        assert x_some is not None\n        x= self.weight.T* x_num\n        if x_cat is not None:\n            x= x[:, np.newaxis, :, :]\n            x= x.permute(0, 1, 3, 2)\n            x= torch.cat([x, self.category_embeddings(x_cat + self.category_offsets[None])], dim= 2,)\n        if self.bias is not None:\n            x= x+ self.bias[None]\n        return x\n\n    def recover(self, Batch, d_numerical):\n        B, L, K= Batch.shape\n        L_new= int(L/ self.d_token)\n        Batch= Batch.reshape(B, L_new, self.d_token)\n        Batch= Batch- self.bias\n        Batch_numerical= Batch[:, :d_numerical, :]\n        Batch_numerical= Batch_numerical/ self.weight\n        Batch_numerical= torch.mean(Batch_numerical, 2, keepdim= False)\n        Batch_cat= Batch[:, d_numerical:, :]\n        new_Batch_cat= torch.zeros([Batch_cat.shape[0], Batch_cat.shape[1]])\n        for i in range(Batch_cat.shape[1]):\n            token_start= self.category_offsets[i]+ 1\n            if i== Batch_cat.shape[1]- 1:\n                token_end= self.category_embeddings.weight.shape[0]- 1\n            else:\n                token_end= self.category_offsets[i+ 1]\n            emb_vec= self.category_embeddings.weight[token_start: token_end+ 1, :]\n            for j in range(Batch_cat.shape[0]):\n                distance= torch.norm(emb_vec- Batch_cat[j, i, :], dim= 1)\n                nearest= torch.argmin(distance)\n                new_Batch_cat[j, i]= nearest+ 1\n            new_Batch_cat= new_Batch_cat.to(Batch_numerical.device)\n        return torch.cat([Batch_numerical, new_Batch_cat], dim= 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Conv1d_with_init(in_channels, out_channels, kernel_size):\n    # Get Conv1d layer\n    layer= nn.Conv1d(in_channels, out_channels, kernel_size)\n    # Weight initialization\n    nn.init.kaiming_normal_(layer.weight)\n    return layer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_torch_trans(heads= 8, layers= 1, channels= 64):\n    encoder_layer= nn.TransformerEncoderLayer(\n        d_model= channels, nhead= heads, dim_feedforward= 64, activation= \"gelu\"\n    )\n    return nn.TransformerEncoder(encoder_layer, num_layers= layers)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DiffusionEmbedding(nn.Module):\n    # Get timestep embedding\n    def __init__(self, num_steps, embedding_dim= 128, projection_dim= None):\n        super().__init__()\n        if projection_dim is None:\n            projection_dim= embedding_dim\n        # The benefits of buffering:\n        # 1. Avoid including parameters that do not require optimization in the trainable parameters of the model\n        # 2. Efficient storage and access\n        # 3. Clearly distinguish between model parameters and auxiliary data\n        self.register_buffer(\"embedding\", self._build_embedding(num_steps, embedding_dim/ 2), persistent= False)\n        self.projection1= nn.Linear(embedding_dim, projection_dim)\n        self.projection2= nn.Linear(projection_dim, projection_dim)\n\n    def forward(self, diffusion_step):\n        x= self.embedding[diffusion_step]\n        x= self.projection1(x)\n        x= F.silu(x)\n        x= self.projection2(x)\n        x= F.silu(x)\n        return x\n\n    # t_embedding(t). The embedding dimension is 128 in total for every time step t.\n    def _build_embedding(self, num_steps, dim= 64):\n        steps= torch.arange(num_steps).unsqueeze(1)  # (T,1)\n        frequencies= 10.0** (torch.arange(dim)/ (dim- 1)* 4.0).unsqueeze(0)  # (1,dim)\n        table= steps* frequencies  # (T,dim)\n        table= torch.cat([torch.sin(table), torch.cos(table)], dim= 1)  # (T,dim*2)\n        return table","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, side_dim, channels, diffusion_embedding_dim, nheads):\n        super().__init__()\n        self.diffusion_projection= nn.Linear(diffusion_embedding_dim, channels)\n        self.cond_projection= Conv1d_with_init(side_dim, 2* channels, 1)\n        self.mid_projection= Conv1d_with_init(channels, 2* channels, 1)\n        self.output_projection= Conv1d_with_init(channels, 2* channels, 1)\n        # Temporal Transformer layer\n        self.time_layer= get_torch_trans(heads= nheads, layers= 1, channels= channels)\n        # Feature Transformer layer\n        self.feature_layer= get_torch_trans(heads= nheads, layers= 1, channels= channels)\n\n    def forward_time(self, y, base_shape):\n        B, channel, K, L= base_shape\n        if L== 1:\n            return y\n        y= y.reshape(B, channel, K, L).permute(0, 2, 1, 3).reshape(B* K, channel, L)\n        # input shape for transformerencoder: [seq, batch, emb]\n        y= self.time_layer(y.permute(2, 0, 1)).permute(1, 2, 0)\n        y= y.reshape(B, K, channel, L).permute(0, 2, 1, 3).reshape(B, channel, K* L)\n        return y\n\n    def forward_feature(self, y, base_shape):\n        B, channel, K, L= base_shape\n        if K== 1:\n            return y\n        y= y.reshape(B, channel, K, L).permute(0, 3, 1, 2).reshape(B* L, channel, K)\n        y= self.feature_layer(y.permute(2, 0, 1)).permute(1, 2, 0)\n        y= y.reshape(B, L, channel, K).permute(0, 2, 3, 1).reshape(B, channel, K* L)\n        return y\n    \n    # x, (B, channels, K, L); cond_info, (B, 49, 1, L); diffusion_emb, (B, emb_dim).\n    def forward(self, x, cond_info, diffusion_emb):\n        B, channel, K, L= x.shape\n        base_shape= x.shape\n        x= x.reshape(B, channel, K* L)\n        # Diffusion embedding processing\n        diffusion_emb= self.diffusion_projection(diffusion_emb).unsqueeze(-1)  # (B,channel,1)\n        # x, (B, channel, KL); diffusion_emb, (B, channel, 1); y, (B, channel, KL).\n        y= x+ diffusion_emb\n        # Temporal transformer\n        y= self.forward_time(y, base_shape)\n        # Feature transformer\n        y= self.forward_feature(y, base_shape)  # (B, channel, K* L)\n        # Combining conditional information\n        y= self.mid_projection(y)  # (B, 2*channel, K* L)\n        _, cond_dim, _, _= cond_info.shape\n        cond_info= cond_info.reshape(B, cond_dim, K* L)\n        cond_info= self.cond_projection(cond_info)  # (B, 2* channel, K* L)\n        y= y+ cond_info\n        # Gated\n        gate, filter= torch.chunk(y, 2, dim= 1)\n        y= torch.sigmoid(gate)* torch.tanh(filter) # y, (B, channel, KL)\n        y= self.output_projection(y)\n        # Residual\n        residual, skip= torch.chunk(y, 2, dim= 1)\n        x= x.reshape(base_shape)\n        residual= residual.reshape(base_shape)\n        skip= skip.reshape(base_shape)\n        return (x+ residual)/ math.sqrt(2.0), skip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class diff_CSDI(nn.Module):\n    def __init__(self, config, inputdim=2):\n        super().__init__()\n        self.config= config\n        self.channels= config[\"channels\"]\n        self.diffusion_embedding= DiffusionEmbedding(num_steps= config[\"num_steps\"], embedding_dim= config[\"diffusion_embedding_dim\"],)\n        self.token_emb_dim= config[\"token_emb_dim\"] if config[\"mixed\"] else 1\n        inputdim= 2* self.token_emb_dim\n        self.input_projection= Conv1d_with_init(inputdim, self.channels, 1)\n        self.output_projection1= Conv1d_with_init(self.channels, self.channels, 1)\n        self.output_projection2= Conv1d_with_init(self.channels, self.token_emb_dim, 1)\n        nn.init.zeros_(self.output_projection2.weight)\n        self.residual_layers= nn.ModuleList(\n            [\n                ResidualBlock(\n                    side_dim= config[\"side_dim\"],\n                    channels= self.channels,\n                    diffusion_embedding_dim= config[\"diffusion_embedding_dim\"],\n                    nheads= config[\"nheads\"],\n                )\n                for _ in range(config[\"layers\"])\n            ]\n        )\n\n    def forward(self, x, cond_info, diffusion_step):\n        B, inputdim, K, L= x.shape\n        x= x.reshape(B, inputdim, K * L)\n        x= self.input_projection(x)\n        x= F.relu(x)\n        x= x.reshape(B, self.channels, K, L)\n        diffusion_emb= self.diffusion_embedding(diffusion_step)\n        skip= []\n        for layer in self.residual_layers:\n            x, skip_connection= layer(x, cond_info, diffusion_emb)\n            skip.append(skip_connection)\n        x= torch.sum(torch.stack(skip), dim= 0)/ math.sqrt(len(self.residual_layers))\n        x= x.reshape(B, self.channels, K* L)\n        x= self.output_projection1(x)\n        x= F.relu(x)\n        x= self.output_projection2(x)\n        if self.config[\"mixed\"]:\n            x= x.permute(0, 2, 1)\n            x= x.reshape(B, K, L* self.token_emb_dim)\n        else:\n            x= x.reshape(B, K, L)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CSDI_base(nn.Module):\n    def __init__(self, exe_name, target_dim, config, device):\n        super().__init__()\n        self.device= device\n        self.target_dim= target_dim\n        # load embedding vector dimension.\n        self.emb_time_dim= config[\"model\"][\"timeemb\"]\n        self.emb_feature_dim= config[\"model\"][\"featureemb\"]\n        self.emb_total_dim= self.emb_time_dim+ self.emb_feature_dim\n        self.is_unconditional= config[\"model\"][\"is_unconditional\"]\n        self.target_strategy= config[\"model\"][\"target_strategy\"]\n        # For categorical variables\n        self.mixed= config[\"model\"][\"mixed\"]\n        if exe_name== \"census\":\n            with open(\"./census_dataset/transformed_columns.pk\", \"rb\") as f:\n                cont_list, num_cate_list= pickle.load(f)\n        self.cont_list= cont_list\n        if self.mixed:\n            self.token_dim= config[\"model\"][\"token_emb_dim\"]\n            # set tokenizer\n            d_numerical= len(cont_list)\n            categories= num_cate_list\n            d_token= self.token_dim\n            token_bias= True\n            self.tokenizer= Tokenizer(d_numerical, categories, d_token, token_bias)\n        if self.is_unconditional== False:\n            self.emb_total_dim+= 1  # for conditional mask\n        self.embed_layer= nn.Embedding(num_embeddings= self.target_dim, embedding_dim= self.emb_feature_dim)\n        config_diff= config[\"diffusion\"]\n        config_diff[\"side_dim\"]= self.emb_total_dim\n        input_dim= 1 if self.is_unconditional== True else 2\n        tot_feature_num= len(cont_list)+ len(num_cate_list)\n        self.diffmodel= diff_CSDI(config_diff, input_dim)\n        # parameters for diffusion models\n        self.num_steps= config_diff[\"num_steps\"]\n        if config_diff[\"schedule\"]== \"quad\":\n            self.beta= (np.linspace(config_diff[\"beta_start\"]** 0.5, config_diff[\"beta_end\"]** 0.5, self.num_steps,)** 2)\n        elif config_diff[\"schedule\"]== \"linear\":\n            self.beta= np.linspace(config_diff[\"beta_start\"], config_diff[\"beta_end\"], self.num_steps)\n        self.alpha_hat = 1 - self.beta\n        self.alpha = np.cumprod(self.alpha_hat)\n        self.alpha_torch = (\n            torch.tensor(self.alpha).float().to(self.device).unsqueeze(1).unsqueeze(1)\n        )\n\n    def time_embedding(self, pos, d_model=128):\n        pe = torch.zeros(pos.shape[0], pos.shape[1], d_model).to(self.device)\n        position = pos.unsqueeze(2)\n        div_term = 1 / torch.pow(10000.0, torch.arange(0, d_model, 2).to(self.device) / d_model)\n        pe[:, :, 0::2] = torch.sin(position * div_term)\n        pe[:, :, 1::2] = torch.cos(position * div_term)\n        return pe\n\n    def get_randmask(self, observed_mask):\n        rand_for_mask = torch.rand_like(observed_mask) * observed_mask\n        rand_for_mask = rand_for_mask.reshape(len(rand_for_mask), -1)\n        for i in range(len(observed_mask)):\n            sample_ratio = np.random.rand()\n            num_observed = observed_mask[i].sum().item()\n            num_masked = round(num_observed * sample_ratio)\n            rand_for_mask[i][rand_for_mask[i].topk(num_masked).indices] = -1\n        cond_mask = (rand_for_mask > 0).reshape(observed_mask.shape).float()\n        return cond_mask\n\n    def get_side_info(self, observed_tp, cond_mask):\n        B, K, L = cond_mask.shape\n        time_embed = self.time_embedding(observed_tp, self.emb_time_dim)  # (B,L,emb)\n        time_embed = time_embed.unsqueeze(2).expand(-1, -1, K, -1)\n        feature_embed = self.embed_layer(torch.arange(self.target_dim).to(self.device))  # (K,emb)\n        feature_embed = feature_embed.unsqueeze(0).unsqueeze(0).expand(B, L, -1, -1)\n        side_info = torch.cat([time_embed, feature_embed], dim=-1)  # (B,L,K,*)\n        side_info = side_info.permute(0, 3, 2, 1)  # (B,*,K,L)\n        if self.is_unconditional == False:\n            side_mask = cond_mask.unsqueeze(1)  # (B,1,K,L)\n            side_info = torch.cat([side_info, side_mask], dim=1)\n        return side_info\n\n    def calc_loss_valid(self, observed_data, cond_mask, observed_mask, side_info, is_train):\n        loss_sum = 0\n        for t in range(self.num_steps):\n            loss = self.calc_loss(observed_data, cond_mask, observed_mask, side_info, is_train, set_t= t)\n            loss_sum += loss.detach()\n        return loss_sum / self.num_steps\n\n    def calc_loss(self, observed_data, cond_mask, observed_mask, side_info, is_train, set_t=-1):\n        B, K, L = observed_data.shape\n        if is_train != 1:\n            t = (torch.ones(B) * set_t).long().to(self.device)\n        else:\n            t = torch.randint(0, self.num_steps, [B]).to(self.device)\n        current_alpha = self.alpha_torch[t]  # (B,1,1)\n        noise = torch.randn_like(observed_data)\n        # Perform forward step. Adding noise to all data.\n        noisy_data = (current_alpha**0.5) * observed_data + (1.0 - current_alpha) ** 0.5 * noise\n        total_input = self.set_input_to_diffmodel(noisy_data, observed_data, cond_mask)\n        predicted = self.diffmodel(total_input, side_info, t)  # (B,K,L*token_dim)\n        target_mask = observed_mask - cond_mask\n        target_mask = torch.repeat_interleave(target_mask, self.token_dim, dim=2)\n        residual = (noise - predicted) * target_mask\n        num_eval = target_mask.sum()\n        loss = (residual**2).sum() / (num_eval if num_eval > 0 else 1)\n        return loss\n\n    def set_input_to_diffmodel(self, noisy_data, observed_data, cond_mask):\n        cond_mask = torch.repeat_interleave(cond_mask, self.token_dim, dim=2)\n        cond_obs = (cond_mask * observed_data).unsqueeze(1)\n        noisy_target = ((1 - cond_mask) * noisy_data).unsqueeze(1)\n        total_input = torch.cat([cond_obs, noisy_target], dim=1)  # (B,2,K,L)\n        B, old_input_dim, K, L = total_input.shape\n        total_input = total_input.reshape(B, old_input_dim, K, int(L / self.token_dim), self.token_dim)\n        total_input = total_input.permute(0, 1, 4, 2, 3)\n        total_input = total_input.reshape(B, old_input_dim * self.token_dim, K, int(L / self.token_dim))\n        return total_input\n\n    def impute(self, observed_data, cond_mask, side_info, n_samples):\n        B, K, L = observed_data.shape\n        cond_mask = torch.repeat_interleave(cond_mask, self.token_dim, dim=2)\n        imputed_samples = torch.zeros(B, n_samples, K, L).to(self.device)\n        # Perform n_samples times of forward and backward pass for same input data.\n        for i in range(n_samples):\n            if self.is_unconditional == True:\n                noisy_obs = observed_data\n                noisy_cond_history = []\n                # perform T steps forward\n                for t in range(self.num_steps):\n                    noise = torch.randn_like(noisy_obs)\n                    noisy_obs = (self.alpha_hat[t] ** 0.5) * noisy_obs + self.beta[t] ** 0.5 * noise\n                    noisy_cond_history.append(noisy_obs * cond_mask)\n            current_sample = torch.randn_like(observed_data)\n            # perform T steps backward\n            for t in range(self.num_steps - 1, -1, -1):\n                if self.is_unconditional == True:\n                    diff_input = (cond_mask * noisy_cond_history[t]+ (1.0 - cond_mask) * current_sample)\n                    diff_input = diff_input.unsqueeze(1)  # (B,1,K,L)\n                else:\n                    # fix original x^{co} as condition\n                    cond_obs = (cond_mask * observed_data).unsqueeze(1)\n                    noisy_target = ((1 - cond_mask) * current_sample).unsqueeze(1)\n                    diff_input = torch.cat([cond_obs, noisy_target], dim=1)  # (B,2,K,L)\n                    B, old_input_dim, K, L = diff_input.shape\n                    diff_input = diff_input.reshape(B, old_input_dim, K, int(L / self.token_dim), self.token_dim)\n                    diff_input = diff_input.permute(0, 1, 4, 2, 3)\n                    diff_input = diff_input.reshape(B, old_input_dim * self.token_dim, K, int(L / self.token_dim))\n                predicted = self.diffmodel(diff_input, side_info, torch.tensor([t]).to(self.device))  # (B,K,L)\n                coeff1 = 1 / self.alpha_hat[t] ** 0.5\n                coeff2 = (1 - self.alpha_hat[t]) / (1 - self.alpha[t]) ** 0.5\n                current_sample = coeff1 * (current_sample - coeff2 * predicted)\n                if t > 0:\n                    noise = torch.randn_like(current_sample)\n                    sigma = ((1.0 - self.alpha[t - 1]) / (1.0 - self.alpha[t]) * self.beta[t]) ** 0.5\n                    current_sample += sigma * noise\n            imputed_samples[:, i] = current_sample.detach()\n        return imputed_samples\n\n    def forward(self, batch, is_train=1):\n        (observed_data, observed_mask, observed_tp, gt_mask, for_pattern_mask, _,)= self.process_data(batch)\n        # In testing, using `gt_mask` (generated with fixed missing rate) as cond_mask.\n        # In training, generate random mask as cond_mask\n        if is_train == 0:\n            cond_mask = gt_mask\n        else:\n            cond_mask = self.get_randmask(observed_mask)\n        side_info = self.get_side_info(observed_tp, cond_mask)\n        # The main calculation procedures are in `self.calc_loss()`\n        loss_func = self.calc_loss if is_train == 1 else self.calc_loss_valid\n        return loss_func(observed_data, cond_mask, observed_mask, side_info, is_train)\n\n    def evaluate(self, batch, n_samples):\n        (observed_data, observed_mask, observed_tp, gt_mask, _, cut_length,)= self.process_data(batch)\n        with torch.no_grad():\n            # gt_mask: 0 for missing elements and manully maksed elements\n            cond_mask= gt_mask\n            # target_mask: 1 for manually masked elements\n            target_mask= observed_mask- cond_mask\n            side_info= self.get_side_info(observed_tp, cond_mask)\n            samples= self.impute(observed_data, cond_mask, side_info, n_samples)\n        return samples, observed_data, target_mask, observed_mask, observed_tp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TabCSDI(CSDI_base):\n    def __init__(self, exe_name, config, device, target_dim= 1):\n        super().__init__(exe_name, target_dim, config, device)\n\n    def process_data(self, batch):\n        # Insert K=1 axis. All mask now with shape (B, 1, L). L=# of attributes.\n        observed_data= batch[\"observed_data\"][:, np.newaxis, :]\n        observed_data= observed_data.to(self.device).float()\n        observed_data= self.tokenizer(observed_data[:, :, self.cont_list], observed_data[:, :, len(self.cont_list) :],)\n        B, K, L, C= observed_data.shape\n        observed_data= observed_data.reshape(B, K, L * C)\n        observed_mask= batch[\"observed_mask\"][:, np.newaxis, :]\n        observed_mask= observed_mask.to(self.device).float()\n        observed_tp= batch[\"timepoints\"].to(self.device).float()\n        gt_mask= batch[\"gt_mask\"][:, np.newaxis, :]\n        gt_mask= gt_mask.to(self.device).float()\n        cut_length= torch.zeros(len(observed_data)).long().to(self.device)\n        for_pattern_mask= observed_mask\n        return (observed_data, observed_mask, observed_tp, gt_mask, for_pattern_mask, cut_length,)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(exe_name, model, config, train_loader, valid_loader= None, valid_epoch_interval= 20, foldername= \"\",):\n    if exe_name== \"census\":\n        with open(\"./census_dataset/transformed_columns.pk\", \"rb\") as f:\n            cont_list, num_cate_list= pickle.load(f)\n        with open(\"./census_dataset/encoder.pk\", \"rb\") as f:\n            encoder= pickle.load(f)\n    # Control random seed in the current script.\n    torch.manual_seed(0)\n    np.random.seed(0)\n    optimizer= Adam(model.parameters(), lr= config[\"lr\"], weight_decay= 1e-6)\n    if foldername!= \"\":\n        output_path= foldername+ \"/model.pth\"\n    p0= int(0.25* config[\"epochs\"])\n    p1= int(0.5* config[\"epochs\"])\n    p2= int(0.75* config[\"epochs\"])\n    p3= int(0.9* config[\"epochs\"])\n    # When the number of training rounds reaches p0, p1, p2, and p3, the learning rate will decay.\n    lr_scheduler= torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones= [p0, p1, p2, p3], gamma= 0.1)\n    history = {'train_loss':[], 'val_loss':[], 'val_rmse':[], 'val_mae':[], 'erro_rate': []}\n    err_total = np.zeros([len(num_cate_list)])\n    err_total_eval_nums = np.zeros([len(num_cate_list)])    \n    best_valid_rmse_erro_rate= 1e10\n    for epoch_no in range(config[\"epochs\"]):\n        train_avg_loss= 0\n        model.train()\n        # The minimum and maximum time intervals for progress bar updates have been specified.\n        with tqdm(train_loader, mininterval= 5.0, maxinterval= 50.0) as it:\n            for batch_no, train_batch in enumerate(it, start= 1):\n                optimizer.zero_grad()\n                # The forward method returns loss.\n                loss= model(train_batch)\n                loss.backward()\n                train_avg_loss+= loss.item()\n                optimizer.step()\n                it.set_postfix(\n                    ordered_dict= {\"avg_epoch_loss\": train_avg_loss/ batch_no, \"epoch\": epoch_no,},\n                    refresh= False,\n                )\n            # step each epoch.\n            lr_scheduler.step()\n\n        if valid_loader is not None and (epoch_no+ 1)% valid_epoch_interval== 0:\n            history['train_loss'].append(train_avg_loss/ batch_no)\n            print(\"Start validation\")\n            model.eval()\n            avg_loss_valid= 0\n            # some initial settings\n            val_nsample= 10\n            val_scaler= 1\n            mse_total= 0\n            mae_total= 0\n            evalpoints_total= 0\n            with torch.no_grad():\n                with tqdm(valid_loader, mininterval= 5.0, maxinterval= 50.0) as it:\n                    for batch_no, valid_batch in enumerate(it, start= 1):\n                        loss= model(train_batch)\n                        avg_loss_valid+= loss.item()\n                        output= model.evaluate(valid_batch, val_nsample)\n                        # `eval_points` is `target_mask`. `observed_time` is `observed_tp`(10)\n                        # `c_target` is `observed_data`\n                        (samples, c_target, eval_points, observed_points, observed_time,)= output\n                        samples= samples.permute(0, 1, 3, 2)\n                        c_target= c_target.permute(0, 2, 1)\n                        eval_points= eval_points.permute(0, 2, 1)\n                        observed_points= observed_points.permute(0, 2, 1)\n                        samples_median= samples.median(dim= 1)\n                        samples_median= model.tokenizer.recover(samples_median.values, len(cont_list))\n                        c_target= model.tokenizer.recover(c_target, len(cont_list))\n                        # for continous variables\n                        mse_current= (((samples_median[:, cont_list] - c_target[:, cont_list])* eval_points[:, cont_list, 0])** 2) * (val_scaler**2)\n                        mae_current= (torch.abs((samples_median[:, cont_list] - c_target[:, cont_list])* eval_points[:, cont_list, 0])) * val_scaler\n                        # for categorical variables\n                        for i in range(len(num_cate_list)):\n                            matched_nums = (samples_median[:, len(cont_list) + i]== c_target[:, len(cont_list) + i]* eval_points[:, len(cont_list) + i, 0]).sum()\n                            eval_nums = eval_points[:, len(cont_list) + i, 0].sum()\n                            err_total[i] += eval_nums - matched_nums\n                            err_total_eval_nums[i] += eval_nums\n                        mse_total += torch.sum(mse_current, dim=0)\n                        mae_total += torch.sum(mae_current, dim=0)\n                        evalpoints_total+= torch.sum(eval_points[:, cont_list, 0], dim=0)\n                        it.set_postfix(\n                            ordered_dict= {\n                                \"rmse_total\": torch.mean(torch.sqrt(torch.div(mse_total, evalpoints_total))).item(),\n                                \"erro_rate\": (err_total/ err_total_eval_nums).mean(),\n                                \"batch_no\": batch_no\n                            },\n                            refresh= True,\n                        )\n                    history['val_rmse'].append(torch.mean(torch.sqrt(torch.div(mse_total, evalpoints_total))).item())\n                    history['val_mae'].append(torch.mean(torch.div(mae_total, evalpoints_total)).item())\n                    history['val_loss'].append(avg_loss_valid/ batch_no)\n                    history['erro_rate'].append((err_total/ err_total_eval_nums).mean())\n                    # save model\n                    if best_valid_rmse_erro_rate> torch.mean(torch.sqrt(torch.div(mse_total, evalpoints_total))).item()+ (err_total/ err_total_eval_nums).mean() and foldername!= \"\":\n                        torch.save(model.state_dict(), output_path)\n    # Use folloing code for saving training history.\n    with open(foldername+'/saved_history.pkl', 'wb') as f:\n        pickle.dump(history, f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_ft(exe_name, model, test_loader, nsample=100, scaler=1, mean_scaler=0, foldername=\"\"):\n    if exe_name == \"census\":\n        with open(\"./census_dataset/transformed_columns.pk\", \"rb\") as f:\n            cont_list, num_cate_list = pickle.load(f)\n        with open(\"./census_dataset/encoder.pk\", \"rb\") as f:\n            encoder = pickle.load(f)\n    print(cont_list, num_cate_list)\n    torch.manual_seed(0)\n    np.random.seed(0)\n    with torch.no_grad():\n        model.eval()\n        mse_total = 0\n        mae_total = 0\n        err_total = np.zeros([len(num_cate_list)])\n        err_total_eval_nums = np.zeros([len(num_cate_list)])\n        evalpoints_total = 0\n        all_target = []\n        all_observed_point = []\n        all_observed_time = []\n        all_evalpoint = []\n        all_generated_samples = []\n        with tqdm(test_loader, mininterval=5.0, maxinterval=50.0) as it:\n            for batch_no, test_batch in enumerate(it, start=1):\n                output = model.evaluate(test_batch, nsample)\n                samples, c_target, eval_points, observed_points, observed_time = output\n                samples = samples.permute(0, 1, 3, 2)  # (B,nsample,L,K)\n                c_target = c_target.permute(0, 2, 1)  # (B,L,K)\n                eval_points = eval_points.permute(0, 2, 1)\n                observed_points = observed_points.permute(0, 2, 1)\n                # take the median from samples.\n                samples_median = samples.median(dim=1)  # (B, L, K)\n                samples_median = model.tokenizer.recover(samples_median.values, len(cont_list))\n                c_target = model.tokenizer.recover(c_target, len(cont_list))\n                all_target.append(c_target)\n                all_evalpoint.append(eval_points)\n                all_observed_point.append(observed_points)\n                all_observed_time.append(observed_time)\n                all_generated_samples.append(samples)\n                # for continous variables\n                mse_current= (((samples_median[:, cont_list] - c_target[:, cont_list])* eval_points[:, cont_list, 0])** 2) * (scaler**2)\n                mae_current= (torch.abs((samples_median[:, cont_list] - c_target[:, cont_list])* eval_points[:, cont_list, 0])) * scaler\n                # for categorical variables\n                for i in range(len(num_cate_list)):\n                    matched_nums = (samples_median[:, len(cont_list) + i]== c_target[:, len(cont_list) + i]* eval_points[:, len(cont_list) + i, 0]).sum()\n                    eval_nums = eval_points[:, len(cont_list) + i, 0].sum()\n                    err_total[i] += eval_nums - matched_nums\n                    err_total_eval_nums[i] += eval_nums\n                mse_total += torch.sum(mse_current, dim=0)\n                mae_total += torch.sum(mae_current, dim=0)\n                evalpoints_total += torch.sum(eval_points[:, cont_list, 0], dim=0)\n                it.set_postfix(\n                    ordered_dict= {\n                        \"rmse_total\": torch.mean(torch.sqrt(torch.div(mse_total, evalpoints_total))).item(),\n                        \"batch_no\": batch_no,\n                    },\n                    refresh= True,\n                )\n\n            with open(foldername + \"/result_nsample\" + str(nsample) + \".pk\", \"wb\") as f:\n                pickle.dump([torch.mean(torch.sqrt(torch.div(mse_total, evalpoints_total))).item(), err_total/ err_total_eval_nums,],f,)\n                print(\"RMSE:\", torch.mean(torch.sqrt(torch.div(mse_total, evalpoints_total))).item(),)\n                print(\"ERR_CATE:\", err_total / err_total_eval_nums)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args.device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nexe_name= \"census\"\nmodel= TabCSDI(exe_name, config, args.device).to(args.device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create folder\ncurrent_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nfoldername = \"./save/census_fold\" + str(args.nfold) + \"_\" + current_time + \"/\"\nprint(\"model folder:\", foldername)\nos.makedirs(foldername, exist_ok=True)\nwith open(foldername + \"config.json\", \"w\") as f:\n    json.dump(config, f, indent=4)\n# Train model\nif args.modelfolder== \"\":\n    train(exe_name, model, config[\"train\"], train_loader, valid_loader= valid_loader, foldername= foldername,)\nelse:\n    model.load_state_dict(torch.load(\"./save/\" + args.modelfolder + \"/model.pth\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"---------------Start testing---------------\")\nevaluate_ft(exe_name, model, test_loader, nsample= args.nsample, scaler= 1, foldername= foldername)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualization of Model Metrics","metadata":{}},{"cell_type":"code","source":"import pickle\nimport matplotlib.pyplot as plt\nwith open(f'{foldername}saved_history.pkl', 'rb') as f:\n    history= pickle.load(f)\nplt.figure(figsize=(8, 6))\nplt.plot(history['train_loss'], label= 'Train Loss')\nplt.plot(history['val_loss'], label= 'Valid Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss value')\nplt.title('Training and Validation Loss over each 20 Epochs')\nplt.legend()\nplt.savefig('Training and Validation Loss.png', dpi=300)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nimport matplotlib.pyplot as plt\nwith open(f'{foldername}saved_history.pkl', 'rb') as f:\n    history= pickle.load(f)\nplt.figure(figsize=(8, 6))\nplt.plot(history['val_rmse'], label= 'Valid RMSE')\nplt.plot(history['val_mae'], label= 'Valid MAE')\nplt.xlabel('Epochs')\nplt.ylabel('Value')\nplt.title('Validation RMSE and MAE over each 20 Epochs')\nplt.legend()\nplt.savefig('Validation RMSE and MAE.png', dpi=300)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tokenizer","metadata":{}},{"cell_type":"code","source":"# partially stole from https://github.com/Yura52/tabular-dl-revisiting-models/blob/main/bin/ft_transformer.py\nclass Tokenizer(nn.Module):\n    def __init__(self, d_numerical: int, categories: ty.Optional[ty.List[int]], d_token: int, bias: bool,)-> None:\n        super().__init__()\n        d_bias= d_numerical+ len(categories)\n        # 9是指该特征有9个取值\n        # [0]+ [9, 16, 8, 15, 6, 5, 2, 42]\n        # tensor([  0,   9,  25,  33,  48,  54,  59,  61, 103])\n        category_offsets= torch.tensor([0]+ categories[:-1]).cumsum(0)\n        # 8\n        self.d_token= d_token\n        self.register_buffer(\"category_offsets\", category_offsets)\n        # (7, 8)\n        self.category_embeddings= nn.Embedding(sum(categories)+ 1, self.d_token)\n        self.category_embeddings.weight.requires_grad= False\n        nn_init.kaiming_uniform_(self.category_embeddings.weight, a= math.sqrt(5))\n        self.weight= nn.Parameter(Tensor(d_numerical, self.d_token))\n        self.weight.requires_grad= False\n        self.bias= nn.Parameter(Tensor(d_bias, self.d_token)) if bias else None\n        nn_init.kaiming_uniform_(self.weight, a= math.sqrt(5))\n        if self.bias is not None:\n            nn_init.kaiming_uniform_(self.bias, a= math.sqrt(5))\n            self.bias.requires_grad= False\n    @property\n    def n_tokens(self)-> int:\n        return len(self.weight)+ (0 if self.category_offsets is None else len(self.category_offsets))\n    # x_num, (B, 8, 6); x_cat, (B, 8, 9). \n    def forward(self, x_num: Tensor, x_cat: ty.Optional[Tensor])-> Tensor:\n        x_some= x_num if x_cat is None else x_cat\n        x_cat= x_cat.type(torch.int32)\n        assert x_some is not None\n        # self.weight.T.shape, (8, 6); x_num, (B, 1, 6);\n        # x, (B, 8, 6).\n        # 数值变量直接embedding\n        x= self.weight.T* x_num\n        # x_cat, (B, 1, 9).\n        if x_cat is not None:\n            # x, (B, 1, 8, 6)\n            x= x[:, np.newaxis, :, :]\n            # x, (B, 1, 6, 8)\n            x= x.permute(0, 1, 3, 2)\n            # x_cat, (B, 1, 9); self.category_offsets[None], (1, 9)\n            # x, torch.cat([(B, 1, 6, 8), (B, 1, 9, 8)])-> (B, 1, 15, 8)\n            # 先跳过之前分类变量的取值数，再embedding\n            x= torch.cat([x, self.category_embeddings(x_cat + self.category_offsets[None])], dim= 2,)\n        if self.bias is not None:\n            x= x+ self.bias[None]\n        return x\n    # d_numerical, 6\n    def recover(self, Batch, d_numerical):\n        # 128, 120, 1\n        B, L, K= Batch.shape\n        # L_new, 15= 120/ 8\n        L_new= int(L/ self.d_token)\n        # Batch, (B, 15, 8)\n        Batch= Batch.reshape(B, L_new, self.d_token)\n        Batch= Batch- self.bias\n        Batch_numerical= Batch[:, :d_numerical, :]\n        # 对数值变量嵌入进行还原, (B, 9, 8), 除以嵌入取平均\n        Batch_numerical= Batch_numerical/ self.weight\n        # Batch_numerical, (B, 9, 8)-> (B, 9)\n        Batch_numerical= torch.mean(Batch_numerical, 2, keepdim= False)\n        # (B, 9, 8)\n        Batch_cat = Batch[:, d_numerical:, :]\n        # (B, 9)\n        new_Batch_cat = torch.zeros([Batch_cat.shape[0], Batch_cat.shape[1]])\n        # for each cata feature\n        for i in range(Batch_cat.shape[1]):\n            # token_start, 1, 10, 26, 34, 49, 55, 60, 62, 104.\n            token_start = self.category_offsets[i] + 1\n            if i == Batch_cat.shape[1] - 1:\n                token_end = self.category_embeddings.weight.shape[0] - 1\n            else:\n                token_end = self.category_offsets[i + 1]\n            # 1, 9\n            print(f'token_start: {token_start}, token_end: {token_end}')\n            # emb_vec, (9, 8).\n            emb_vec = self.category_embeddings.weight[token_start : token_end + 1, :]\n            # 量化操作(根据嵌入的距离，为学到的嵌入分配固定嵌入)\n            for j in range(Batch_cat.shape[0]):\n                distance = torch.norm(emb_vec - Batch_cat[j, i, :], dim=1)\n                nearest = torch.argmin(distance)\n                new_Batch_cat[j, i] = nearest + 1\n            new_Batch_cat = new_Batch_cat.to(Batch_numerical.device)\n        return torch.cat([Batch_numerical, new_Batch_cat], dim=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"./census_dataset/transformed_columns.pk\", \"rb\") as f:\n    cont_list, num_cate_list = pickle.load(f)\ntok= Tokenizer(6, num_cate_list, config[\"model\"][\"token_emb_dim\"], True)\nprint(num_cate_list)\nprint(torch.tensor([0]+ num_cate_list[:-1]).cumsum(0)[None])\nobserved_data= next(iter(test_loader))['observed_data'][:, np.newaxis, :]\n# (B, K, L)\nprint(f'{observed_data.shape}')\nprint(f'original data: {observed_data[0]}')\nobserved_data= tok(\n    observed_data[:, :, cont_list],\n    observed_data[:, :, len(cont_list):],\n)\nprint(f'encoding data: {observed_data[0, 0].shape}')\nobserved_data= observed_data.view(observed_data.shape[0], -1).unsqueeze(-1)\ncovered_data= tok.recover(observed_data, 6)\nprint(f'recovered data: {covered_data[0]}')","metadata":{},"execution_count":null,"outputs":[]}]}